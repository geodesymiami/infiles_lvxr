{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "poseis-20y.dat\n",
      "poseis-20y_10y_vertical.txt\n",
      "poseis-30y.dat\n",
      "poseis-30y_20y_vertical.txt\n",
      "poseis-40y.dat\n",
      "poseis-40y_30y_vertical.txt\n",
      "poseis-50y.dat\n",
      "poseis-50y_40y_vertical.txt\n",
      "poseis-60y.dat\n",
      "poseis-60y_50y_vertical.txt\n",
      "poseis-70y.dat\n",
      "poseis-70y_60y_vertical.txt\n",
      "poseis-80y.dat\n",
      "poseis-80y_70y_vertical.txt\n",
      "poseis-94y.dat\n",
      "poseis-94y_80y_vertical.txt\n",
      "poseis-now.dat\n",
      "poseis-now_94y_vertical.txt\n",
      "poseis-10y.dat\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def generate_lat_lon_file(data, row, colom, outpath):\n",
    "    \"\"\"read coseismic.dat file and generate lat.txt and lon.txt\"\"\"\n",
    "    lat = []\n",
    "    lon = []\n",
    "    df = pd.read_csv(data,sep='\\s+')\n",
    "    disp_lat = np.array(df['Lat[deg]'])\n",
    "    disp_lon = np.array(df['Lon[deg]'])\n",
    "        \n",
    "    lat_tmp = disp_lat.reshape(disp_lat.shape[0],1)\n",
    "    lat = np.transpose(lat_tmp.reshape(80,50))\n",
    "    \n",
    "    lon_tmp = disp_lon.reshape(disp_lon.shape[0],1)\n",
    "    lon = np.transpose(lon_tmp.reshape(80,50))\n",
    "    \n",
    "    # another method to get lat and lon txt with same organized pattern\n",
    "    #lat_unique = np.array(df['Lat[deg]'])[0:row]\n",
    "    #lon_unique = np.unique(np.array(df['Lon[deg]']))\n",
    "    #lat = np.transpose(np.tile(lat_unique,(colom,1)))\n",
    "    #lon = np.tile(lon_unique,(row,1))\n",
    "    \n",
    "    #save into txt \n",
    "    np.savetxt(outpath+'/lat.txt', lat, fmt='%.4f', delimiter=' ')\n",
    "    np.savetxt(outpath+'/lon.txt', lon, fmt='%.4f', delimiter=' ')\n",
    "\n",
    "def read_displacement_data(data,row,colom):\n",
    "    \"\"\"read displacement in SN EW and UP direction\"\"\"\n",
    "    df = pd.read_csv(data,sep='\\s+')\n",
    "    displ_SN = np.array(df['Ux'])\n",
    "    displ_ES = np.array(df['Uy'])\n",
    "    displ_UP = np.array(df['Uz'])\n",
    "    # reorganized displacment field   \n",
    "    SN_tmp = displ_SN.reshape(displ_SN.shape[0],1)\n",
    "    SN = np.transpose(SN_tmp.reshape(colom,row))\n",
    "    \n",
    "    ES_tmp = displ_ES.reshape(displ_ES.shape[0],1)\n",
    "    ES = np.transpose(ES_tmp.reshape(colom,row))\n",
    "    \n",
    "    UP_tmp = displ_UP.reshape(displ_UP.shape[0],1)\n",
    "    UP = np.transpose(UP_tmp.reshape(colom,row))\n",
    "    \n",
    "    return SN, ES, UP\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    workdir = '/home/lvxr/insarlab/jupyter/lab/LargeEarthquake/MODEL/model4/Haiyuan/PS_dat/'\n",
    "    outpath = '/home/lvxr/insarlab/jupyter/lab/LargeEarthquake/MODEL/model4/Haiyuan/PS_dat/'\n",
    "    row = 50\n",
    "    colom = 80\n",
    "    # count poseis*.dat files\n",
    "    dat_num = []\n",
    "    key = 'poseis'\n",
    "    for filename in os.listdir(workdir):\n",
    "        if os.path.splitext(filename)[1] == '.dat' and str.find(filename,key) != -1:\n",
    "            dat_num.append(filename)\n",
    "    print(len(dat_num))\n",
    "    dat_num.sort()\n",
    "    \n",
    "    #generate lat and lon \n",
    "    generate_lat_lon_file(workdir+'coseis.dat',row, colom,outpath)\n",
    "    \n",
    "    # generate postseismic deformation between two time period\n",
    "    datfile_number = len(dat_num)\n",
    "\n",
    "    for number in range(1,datfile_number):\n",
    "        print(dat_num[number])\n",
    "        post_displ_last_sn,post_displ_last_es,post_displ_last_up = read_displacement_data(workdir+dat_num[number],row,colom)\n",
    "        post_displ_former_sn,post_displ_former_es,post_displ_former_up = read_displacement_data(workdir+dat_num[number-1],row,colom)\n",
    "        post_displ_timeperiod = post_displ_last_up - post_displ_former_up\n",
    "        # save file\n",
    "        save_name = dat_num[number].split('.')[0]+'_'+(dat_num[number-1].split('.')[0]).split(\"-\")[1]+'_vertical.txt'\n",
    "        print(save_name)\n",
    "        np.savetxt(outpath+save_name, np.flipud(post_displ_timeperiod), fmt='%.6f', delimiter=' ')\n",
    "    # process the first post seismic data\n",
    "    print(dat_num[0])\n",
    "    post_displ_up = read_displacement_data(workdir+dat_num[0],row,colom)[2]\n",
    "    coseis_displ_up = read_displacement_data(workdir+'coseis.dat',row,colom)[2]\n",
    "    post_displ_timeperiod = post_displ_up - coseis_displ_up\n",
    "    save_name = dat_num[0].split('.')[0]+'_0y_vertical.txt'\n",
    "    np.savetxt(outpath+save_name, np.flipud(post_displ_timeperiod), fmt='%.6f', delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
